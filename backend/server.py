import os
from pathlib import Path
from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
import openai
import logging
logging.basicConfig(level=logging.INFO)


HERE = Path(__file__).parent
load_dotenv(HERE / ".env")

openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω OPENAI_API_KEY –≤ —Ñ–∞–π–ª–µ .env")

app = FastAPI()

class AnnotationRequest(BaseModel):
    selectedText: str
    fullText:     str

class AnnotationResponse(BaseModel):
    annotation: str

@app.post("/api/annotate", response_model=AnnotationResponse)
async def annotate(req: AnnotationRequest):
    prompt = (
        "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø–µ—Å–µ–Ω.\n"
        f"–§—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏:\n{req.selectedText}\n\n"
        "–î–∞–π –∫–æ—Ä–æ—Ç–∫—É—é, –Ω–æ —ë–º–∫—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é —ç—Ç–æ–≥–æ –æ—Ç—Ä—ã–≤–∫–∞."
        )
    try:
        resp = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
            {"role": "system", "content": "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø–µ—Å–µ–Ω."},
            {"role": "user",   "content": prompt},
            ],
            max_tokens=200,
            temperature=0.7,
        )
        return {"annotation": resp.choices[0].message.content.strip()}
    except Exception as e:
        logging.exception("üí• error in /api/annotate")
        raise HTTPException(status_code=500, detail=str(e))

frontend_dir = HERE / "frontend"
app.mount(
    "/",
    StaticFiles(directory=str(frontend_dir), html=True),
    name="frontend"
)

# uvicorn server:app --reload --host 0.0.0.0 --port 8000
